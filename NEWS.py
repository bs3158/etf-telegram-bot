import os
import feedparser
import requests
from bs4 import BeautifulSoup
import re
from googletrans import Translator

# í™˜ê²½ ë³€ìˆ˜
BOT_TOKEN = os.environ.get("BOT_TOKEN")
CHAT_ID = os.environ.get("CHAT_ID")

# 4ê°œì˜ ì‚¬ì´íŠ¸ ì„¤ì •
RSS_LIST = [
    "https://www.hani.co.kr/rss/",    # í•œê²¨ë ˆ ê²½ì œ
    "https://www.hankyung.com/feed/economy",   # í•œêµ­ê²½ì œ
    "https://www.mk.co.kr/rss/30000001/",      # ë§¤ì¼ê²½ì œ
    "http://rss.cnn.com/rss/edition.rss"       # âš ï¸ 404 ì˜¤ë¥˜ê°€ ì—†ëŠ” CNN ìµœì‹  ì¢…í•© í”¼ë“œë¡œ ë³€ê²½
]

translator = Translator()

def translate_text(text):
    try:
        if not text or text.strip() == "": return text
        result = translator.translate(text, dest='ko')
        return result.text
    except:
        return text

def get_summary(url):
    """êµ­ë‚´ ì‹ ë¬¸ì‚¬ ë³¸ë¬¸ ìš”ì•½ ë¡œì§"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        r = requests.get(url, timeout=8, headers=headers)
        r.encoding = 'utf-8'
        soup = BeautifulSoup(r.text, "html.parser")

        for s in soup(['script', 'style', 'header', 'footer', 'nav', 'aside']):
            s.decompose()

        text = soup.get_text(" ", strip=True)
        sentences = re.split(r'(?<=[.!?])\s+', text)
        valid_sentences = [s for s in sentences if 40 < len(s) < 200]
        summary = " ".join(valid_sentences[:2])
        return summary if summary else "ë³¸ë¬¸ ìš”ì•½ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except:
        return "ìš”ì•½ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

def collect_and_send():
    all_chunks = []

    for rss_url in RSS_LIST:
        feed = feedparser.parse(rss_url)
        source_news = []
        for entry in feed.entries[:5]:
            # RSSì—ì„œ ì œê³µí•˜ëŠ” ìš”ì•½ë¬¸ í™•ë³´
            rss_summary = getattr(entry, 'summary', '') or getattr(entry, 'description', '')
            source_news.append({
                "title": entry.title,
                "link": entry.link,
                "rss_summary": rss_summary
            })
        all_chunks.append(source_news)

    for i, chunk in enumerate(all_chunks):
        current_num = i + 1
        source_name = ["í•œê²¨ë ˆ", "í•œêµ­ê²½ì œ", "ë§¤ì¼ê²½ì œ", "CNN(í•´ì™¸)"][i]

        message = f"<b>ğŸš€ ì‹¤ì‹œê°„ ì£¼ìš” ë‰´ìŠ¤ ({current_num}/4) - {source_name}</b>\n\n"

        for idx, item in enumerate(chunk):
            title = item['title']
            
            # CNN(4ë²ˆì§¸)ì€ RSS ìš”ì•½ ì‚¬ìš© (ë³´ì•ˆ ì°¨ë‹¨ ë°©ì§€)
            if current_num == 4:
                summary = re.sub('<[^<]+?>', '', item['rss_summary']).strip()
                if not summary: summary = "ê¸°ì‚¬ ë§í¬ë¥¼ í†µí•´ ìì„¸í•œ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”."
            else:
                summary = get_summary(item['link'])

            if current_num == 4 or re.search('[a-zA-Z]{7,}', title):
                title = f"[ë²ˆì—­] " + translate_text(title)
                summary = translate_text(summary)

            message += f"<b>{idx+1}. {title}</b>\n"
            message += f"ğŸ“ {summary}\n"
            message += f"ğŸ”— <a href='{item['link']}'>ê¸°ì‚¬ ë³´ê¸°</a>\n\n"
            message += "--------------------------\n\n"

        send_to_telegram(message)

def send_to_telegram(text):
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    payload = {
        "chat_id": CHAT_ID,
        "text": text,
        "parse_mode": "HTML",
        "disable_web_page_preview": True
    }
    requests.post(url, data=payload)

if __name__ == "__main__":
    collect_and_send()
