import os
import feedparser
import requests
from bs4 import BeautifulSoup
import re
from googletrans import Translator # ë²ˆì—­ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€

# í™˜ê²½ ë³€ìˆ˜
BOT_TOKEN = os.environ.get("BOT_TOKEN")
CHAT_ID = os.environ.get("CHAT_ID")

RSS_LIST = [
    "https://www.hani.co.kr/rss/",  # í•œê²¨ë ˆ ê²½ì œ
    "https://www.hankyung.com/feed/economy", # í•œêµ­ê²½ì œ
    "https://www.mk.co.kr/rss/30000001/",    # ë§¤ì¼ê²½ì œ
    "https://www.cnbc.com/id/10001147/device/rss/rss.html" # CNBC (ì˜ì–´)
]

translator = Translator()

def translate_text(text):
    try:
        # í…ìŠ¤íŠ¸ê°€ ì˜ì–´ì¸ì§€ í™•ì¸ í›„ í•œêµ­ì–´ë¡œ ë²ˆì—­
        result = translator.translate(text, dest='ko')
        return result.text
    except:
        return text # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ë¬¸ ë°˜í™˜

def get_summary(url):
    try:
        # ë¸Œë¼ìš°ì €ì¸ ê²ƒì²˜ëŸ¼ ì†ì´ëŠ” í—¤ë” ì¶”ê°€ (ë§¤ìš° ì¤‘ìš”)
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        r = requests.get(url, timeout=10, headers=headers)
        r.encoding = 'utf-8' # í•œê¸€ ê¹¨ì§ ë°©ì§€
        
        soup = BeautifulSoup(r.text, "html.parser")
        
        # ê¸°ì‚¬ ë³¸ë¬¸ ì™¸ ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±°
        for s in soup(['script', 'style', 'header', 'footer', 'nav', 'aside']):
            s.decompose()

        text = soup.get_text(" ", strip=True)
        # í•µì‹¬ ë¬¸ì¥ ì¶”ì¶œ ë¡œì§
        sentences = re.split(r'(?<=[.!?])\s+', text)
        valid_sentences = [s for s in sentences if len(s) > 40 and len(s) < 200]
        
        summary = " ".join(valid_sentences[:2]) # ìƒìœ„ 2ë¬¸ì¥ ì¶”ì¶œ
        return summary if summary else "ë³¸ë¬¸ì„ ìš”ì•½í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        return f"ìš”ì•½ ì‹¤íŒ¨ (ì‚¬ìœ : {str(e)})"

def collect_and_send():
    all_news = []
    for rss in RSS_LIST:
        feed = feedparser.parse(rss)
        # ì†ŒìŠ¤ë‹¹ ê¸°ì‚¬ë¥¼ ì¶©ë¶„íˆ ê°€ì ¸ì˜¨ ë’¤ ë‚˜ì¤‘ì— 20ê°œë¡œ ìë¦…ë‹ˆë‹¤.
        for entry in feed.entries[:10]: 
            all_news.append({"title": entry.title, "link": entry.link})

    # ì´ 20ê°œë¡œ ì œí•œí•˜ë˜, ìˆ˜ì§‘ëœ ê²Œ 20ê°œë³´ë‹¤ ì ì„ ìƒí™©ë„ ëŒ€ë¹„í•©ë‹ˆë‹¤.
    target_news = all_news[:20]
    total_articles = len(target_news)
    
    # 5ê°œì”© ë¬¶ì„ ë•Œ ì´ ëª‡ ê°œì˜ ë©”ì‹œì§€ê°€ ìƒì„±ë ì§€ ë¯¸ë¦¬ ê³„ì‚°
    chunk_size = 5
    # total_chunks ê³„ì‚°: (ì „ì²´ ê°œìˆ˜ + 4) // 5 ë°©ì‹ (ì˜¬ë¦¼ ì²˜ë¦¬)
    total_chunks = (total_articles + chunk_size - 1) // chunk_size

    for i in range(0, total_articles, chunk_size):
        chunk = target_news[i:i+chunk_size]
        current_chunk_num = (i // chunk_size) + 1
        
        # ìƒë‹¨ í‘œê¸°: [í˜„ì¬ ë²ˆí˜¸ / ì „ì²´ ë²ˆí˜¸]
        message = f"<b>ğŸš€ ì‹¤ì‹œê°„ ì£¼ìš” ë‰´ìŠ¤ ({current_chunk_num}/{total_chunks})</b>\n\n"
        
        for idx, item in enumerate(chunk):
            title = item['title']
            summary = get_summary(item['link'])
            
            # ì˜ë¬¸ ë‰´ìŠ¤ ìë™ ê°ì§€ ë° ë²ˆì—­ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
            if re.search('[a-zA-Z]{5,}', title): # ì•ŒíŒŒë²³ 5ì ì´ìƒ ì—°ì† ì‹œ ì˜ì–´ë¡œ ê°„ì£¼
                title = f"[ë²ˆì—­] " + translate_text(title)
                summary = translate_text(summary)

            message += f"<b>{idx+1}. {title}</b>\n"
            message += f"ğŸ“ {summary}\n"
            message += f"ğŸ”— <a href='{item['link']}'>ê¸°ì‚¬ ë³´ê¸°</a>\n\n"
            message += "--------------------------\n\n"
        
        send_to_telegram(message)

def send_to_telegram(text):
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    payload = {"chat_id": CHAT_ID, "text": text, "parse_mode": "HTML", "disable_web_page_preview": True}
    requests.post(url, data=payload)

if __name__ == "__main__":
    collect_and_send()
