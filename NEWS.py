import os
import feedparser
import requests
from bs4 import BeautifulSoup
import re
from googletrans import Translator

# í™˜ê²½ ë³€ìˆ˜
BOT_TOKEN = os.environ.get("BOT_TOKEN")
CHAT_ID = os.environ.get("CHAT_ID")

# 4ê°œì˜ ì‚¬ì´íŠ¸ ì„¤ì •
RSS_LIST = [
    "https://www.hani.co.kr/rss/",    # í•œê²¨ë ˆ ê²½ì œ
    "https://www.hankyung.com/feed/economy",   # í•œêµ­ê²½ì œ
    "https://www.mk.co.kr/rss/30000001/",      # ë§¤ì¼ê²½ì œ
    "http://rss.cnn.com/rss/edition_business.rss" # CNN ìµœì‹  ë¹„ì¦ˆë‹ˆìŠ¤ RSS
]

translator = Translator()

def translate_text(text):
    try:
        if not text or text.strip() == "": return text
        result = translator.translate(text, dest='ko')
        return result.text
    except:
        return text

def get_summary(url):
    """êµ­ë‚´ ì‹ ë¬¸ì‚¬ ë³¸ë¬¸ ìš”ì•½ ë¡œì§"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        r = requests.get(url, timeout=8, headers=headers)
        r.encoding = 'utf-8'
        soup = BeautifulSoup(r.text, "html.parser")

        for s in soup(['script', 'style', 'header', 'footer', 'nav', 'aside']):
            s.decompose()

        text = soup.get_text(" ", strip=True)
        sentences = re.split(r'(?<=[.!?])\s+', text)
        valid_sentences = [s for s in sentences if 40 < len(s) < 200]
        summary = " ".join(valid_sentences[:2])
        return summary if summary else "ë³¸ë¬¸ ìš”ì•½ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except:
        return "ìš”ì•½ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

def collect_and_send():
    all_chunks = []

    for rss_url in RSS_LIST:
        feed = feedparser.parse(rss_url)
        source_news = []
        for entry in feed.entries[:5]:
            # --- CNN êµ¬í˜• ë§í¬(money.cnn.com)ë¥¼ ì‹ í˜• ë§í¬ë¡œ ê°•ì œ ë³€í™˜ ---
            link = entry.link
            if "money.cnn.com" in link:
                # money.cnn.com/2017/... í˜•ì‹ì„ edition.cnn.com/business/... í˜•ì‹ìœ¼ë¡œ ì¶”ì • ë³€í™˜
                # í•˜ì§€ë§Œ ê°€ì¥ í™•ì‹¤í•œ ë°©ë²•ì€ RSSì—ì„œ ì£¼ëŠ” ì›ë³¸ ë§í¬ë¥¼ ê·¸ëŒ€ë¡œ ì‹ ë¢°í•˜ë˜ ë„ë©”ì¸ë§Œ êµì²´ ì‹œë„
                link = link.replace("money.cnn.com", "edition.cnn.com/business")
            
            rss_summary = getattr(entry, 'summary', '') or getattr(entry, 'description', '')
            source_news.append({
                "title": entry.title,
                "link": link,
                "rss_summary": rss_summary
            })
        all_chunks.append(source_news)

    for i, chunk in enumerate(all_chunks):
        current_num = i + 1
        source_name = ["í•œê²¨ë ˆ", "í•œêµ­ê²½ì œ", "ë§¤ì¼ê²½ì œ", "CNN(í•´ì™¸)"][i]

        message = f"<b>ğŸš€ ì‹¤ì‹œê°„ ì£¼ìš” ë‰´ìŠ¤ ({current_num}/4) - {source_name}</b>\n\n"

        for idx, item in enumerate(chunk):
            title = item['title']
            
            # CNNì€ RSS ìš”ì•½ ì‚¬ìš©, êµ­ë‚´ ë§¤ì²´ëŠ” ë³¸ë¬¸ í¬ë¡¤ë§ ìš”ì•½ ì‚¬ìš©
            if current_num == 4:
                summary = re.sub('<[^<]+?>', '', item['rss_summary']).strip()
                if not summary: summary = "ìµœì‹  ì„¸ë¶€ì •ë³´ëŠ” ê¸°ì‚¬ ë§í¬ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”."
            else:
                summary = get_summary(item['link'])

            if current_num == 4 or re.search('[a-zA-Z]{7,}', title):
                title = f"[ë²ˆì—­] " + translate_text(title)
                summary = translate_text(summary)

            message += f"<b>{idx+1}. {title}</b>\n"
            message += f"ğŸ“ {summary}\n"
            message += f"ğŸ”— <a href='{item['link']}'>ê¸°ì‚¬ ë³´ê¸°</a>\n\n"
            message += "--------------------------\n\n"

        send_to_telegram(message)

def send_to_telegram(text):
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    payload = {
        "chat_id": CHAT_ID,
        "text": text,
        "parse_mode": "HTML",
        "disable_web_page_preview": True
    }
    requests.post(url, data=payload)

if __name__ == "__main__":
    collect_and_send()
